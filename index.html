---
layout: default
title: Robo-Troj: A Novel Multi-Triggered Backdoor Attack against Domain-Specific
---

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{{ page.title }}</title>
</head>
<body>
    <h1>Robo-Troj: A Novel Multi-Triggered Backdoor Attack against Domain-Specific</h1>
    <p>Robot task planning  using Large Language Models (LLMs) is an emerging field in which robots query the LLM to generate a task plan and then execute the plan to transition from an initial to a final state. While LLMs are powerful, they still require domain-specific fine-tuning to adapt them to a given task domain for a robot. To efficiently adapt these LLMs to domain-specific tasks, Soft-Prompt Tuning (SPT) has emerged as a memory and energy-efficient candidate that tunes a small set of parameters on top of a frozen pre-trained LLM to adapt it to a robotics task. This setting leads to a research question in our investigation: how safe are these robots in case of a compromised LLM being attacked at the SPT stage? To answer this, we design a novel multi-trigger backdoor attack to exhibit that an attacker having access to the SPT stage can compromise the performance of LLM in robot task planning. Our proposed attack \textit{\ourtitle} consists of a two-stage attack mechanism. First, during the SPT stage, we design a novel algorithm called \textit{multi-trigger backdoor optimization (MBO)} which for the first time, trains a parametric trigger distribution for a given vocabulary, dataset and model. Then, the attacker can efficiently sample multiple triggers from the pre-trained trigger distribution and embed the malicious backdoor into the LLM by tuning only the soft prompt. Finally, at the deployment stage, the attack is activated using one of those trigger words to compromise the robot's performance by generating and executing a harmful sequence of tasks. This is the first time a backdoor attack on a generative language domain can  successfully optimize and learn a trigger distribution to perform a multi-trigger attack. We extensively evaluate the performance of the attack on multiple SOTA LLMs and provide a real robot demo~\footnote{\url{https://robo-troj.github.io/}} exhibiting $\sim$100\% attack success rate without hampering the regular (i.e., no attack) operation, again for the first time highlighting the vulnerability of robot task planning systems adopting LLM.</p>
</body>
</html>
